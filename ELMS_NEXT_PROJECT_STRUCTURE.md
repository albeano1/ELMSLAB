# ELMS-NEXT: High-Performance Logical Reasoning System

## ðŸŽ¯ Project Overview
A high-accuracy, high-speed logical reasoning system that replaces Vectionary with custom-trained models and optimized parsing engines. Target: <10ms latency, >99% accuracy, >1000 req/s throughput.

## ðŸ“š Current System Context

### **What is Vectionary?**
Vectionary is a semantic parsing API service that converts natural language into structured semantic trees with:
- **Semantic roles**: agent, patient, theme, modifier, goal, etc.
- **POS tags**: NOUN, VERB, ADJ, ADV, PRON, etc.
- **Dependency relationships**: root, modifier, complement, etc.
- **Definitions**: Word definitions and semantic information
- **Tree structure**: Hierarchical representation of sentence structure

**Current Vectionary Integration:**
```python
# Current ELMS.py implementation
class VectionaryAPIClient:
    """Handles communication with Vectionary parsing API"""
    ENDPOINTS = {
        'prod': 'https://us-central1-parsimony-server.cloudfunctions.net/arborize/arborize/mod1'
    }
    
    def get_trees(self, text: str) -> List[Dict]:
        """Get semantic trees from Vectionary API"""
        # Makes HTTP requests to Vectionary service
        # Returns structured semantic trees

class VectionaryParser:
    """Parses text using Vectionary trees into logical formulas"""
    
    def parse(self, text: str) -> ParsedStatement:
        """Parse text into logical statement using Vectionary"""
        trees = self.api_client.get_trees(text)
        # Extract semantic roles, POS tags, dependencies
        # Convert to Prolog facts/rules
```

**Current System Architecture:**
```
ELMSLAB/
â”œâ”€â”€ ELMS.py                    # Core dynamic converter + Vectionary integration
â”œâ”€â”€ serv_vectionary.py         # FastAPI server with Vectionary calls
â”œâ”€â”€ prolog_reasoner.py         # Prolog inference engine
â”œâ”€â”€ vectionary_knowledge_base.py # Knowledge base management
â”œâ”€â”€ elms-chat-react/           # React web interface
â””â”€â”€ tests/                     # Test suite
```

**Vectionary Limitations (Why We Need ELMS-NEXT):**
1. **Network Dependency**: Requires internet connection and API calls
2. **Latency**: 100-500ms per parsing request
3. **Rate Limits**: API throttling and usage limits
4. **Cost**: Per-request pricing model
5. **Reliability**: External service dependency
6. **Customization**: Limited control over parsing logic
7. **Offline Usage**: Cannot work without internet

**ELMS-NEXT Goals:**
- Replace Vectionary API calls with local models
- Achieve <10ms parsing latency (50x faster)
- Enable offline operation
- Provide unlimited usage
- Allow custom model training
- Maintain >99% accuracy on logical reasoning

## ðŸ“ Project Structure

```
ELMS-NEXT/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”‚
â”œâ”€â”€ core/                                    # Core reasoning engine
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ semantic_parser/                     # Enhanced semantic parsing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ hybrid_parser.py                # Main hybrid parser
â”‚   â”‚   â”œâ”€â”€ rule_based_parser.py            # Fast rule-based parsing
â”‚   â”‚   â”œâ”€â”€ pattern_matcher.py              # Pattern matching engine
â”‚   â”‚   â”œâ”€â”€ cache_manager.py                # Parsing cache
â”‚   â”‚   â””â”€â”€ sentence_structure_detector.py  # Custom structure detection
â”‚   â”‚
â”‚   â”œâ”€â”€ logic_engine/                       # High-speed Prolog engine
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ optimized_prolog.py             # Custom Prolog engine
â”‚   â”‚   â”œâ”€â”€ fact_index.py                   # O(1) fact lookup
â”‚   â”‚   â”œâ”€â”€ rule_compiler.py                # Compiled rules
â”‚   â”‚   â”œâ”€â”€ query_optimizer.py              # Query optimization
â”‚   â”‚   â””â”€â”€ parallel_executor.py            # Parallel query execution
â”‚   â”‚
â”‚   â”œâ”€â”€ knowledge_graph/                    # Graph-based knowledge
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ graph_engine.py                 # Main graph engine
â”‚   â”‚   â”œâ”€â”€ entity_index.py                 # Entity indexing
â”‚   â”‚   â”œâ”€â”€ relation_index.py               # Relation indexing
â”‚   â”‚   â””â”€â”€ property_index.py               # Property indexing
â”‚   â”‚
â”‚   â”œâ”€â”€ inference_engine/                   # Multi-strategy inference
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ forward_chaining.py             # Forward chaining
â”‚   â”‚   â”œâ”€â”€ backward_chaining.py            # Backward chaining
â”‚   â”‚   â”œâ”€â”€ resolution_engine.py            # Resolution theorem proving
â”‚   â”‚   â””â”€â”€ hybrid_inference.py             # Combined strategies
â”‚   â”‚
â”‚   â””â”€â”€ utils/                              # Core utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ text_preprocessor.py            # Text preprocessing
â”‚       â”œâ”€â”€ pattern_utils.py                # Pattern utilities
â”‚       â””â”€â”€ performance_monitor.py          # Performance monitoring
â”‚
â”œâ”€â”€ models/                                 # Custom trained models
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ semantic_classifier/                # Semantic pattern classification
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ model.py                        # Model architecture
â”‚   â”‚   â”œâ”€â”€ trainer.py                      # Training pipeline
â”‚   â”‚   â”œâ”€â”€ data_generator.py               # Training data generation
â”‚   â”‚   â””â”€â”€ inference.py                    # Model inference
â”‚   â”‚
â”‚   â”œâ”€â”€ relation_extractor/                 # Relation extraction
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ model.py                        # Relation extraction model
â”‚   â”‚   â”œâ”€â”€ trainer.py                      # Training pipeline
â”‚   â”‚   â”œâ”€â”€ data_augmenter.py               # Data augmentation
â”‚   â”‚   â””â”€â”€ inference.py                    # Extraction inference
â”‚   â”‚
â”‚   â”œâ”€â”€ query_optimizer/                    # Query optimization
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ model.py                        # Optimization model
â”‚   â”‚   â”œâ”€â”€ trainer.py                      # Training pipeline
â”‚   â”‚   â””â”€â”€ inference.py                    # Query optimization
â”‚   â”‚
â”‚   â””â”€â”€ sentence_structure/                 # Sentence structure detection
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ dependency_parser.py            # Dependency parsing
â”‚       â”œâ”€â”€ constituency_parser.py          # Constituency parsing
â”‚       â”œâ”€â”€ semantic_role_labeler.py        # Semantic role labeling
â”‚       â”œâ”€â”€ pos_tagger.py                   # POS tagging
â”‚       â””â”€â”€ named_entity_recognizer.py      # NER
â”‚
â”œâ”€â”€ api/                                    # High-performance API
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                             # FastAPI application
â”‚   â”œâ”€â”€ routes/                             # API routes
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ reasoning.py                    # Reasoning endpoints
â”‚   â”‚   â”œâ”€â”€ knowledge.py                    # Knowledge management
â”‚   â”‚   â””â”€â”€ health.py                       # Health checks
â”‚   â”œâ”€â”€ middleware/                         # API middleware
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ caching.py                      # Response caching
â”‚   â”‚   â”œâ”€â”€ rate_limiting.py                # Rate limiting
â”‚   â”‚   â””â”€â”€ monitoring.py                   # Performance monitoring
â”‚   â””â”€â”€ schemas/                            # Pydantic schemas
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ requests.py                     # Request schemas
â”‚       â””â”€â”€ responses.py                    # Response schemas
â”‚
â”œâ”€â”€ web/                                    # Next-gen React interface
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.tsx
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â”œâ”€â”€ components/                     # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterface.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ MessageList.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ InputArea.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ KnowledgeGraph.tsx
â”‚   â”‚   â”‚   â””â”€â”€ PerformanceMonitor.tsx
â”‚   â”‚   â”œâ”€â”€ hooks/                          # Custom React hooks
â”‚   â”‚   â”‚   â”œâ”€â”€ useReasoning.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ useKnowledge.ts
â”‚   â”‚   â”‚   â””â”€â”€ usePerformance.ts
â”‚   â”‚   â”œâ”€â”€ services/                       # API services
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ reasoning.ts
â”‚   â”‚   â”‚   â””â”€â”€ knowledge.ts
â”‚   â”‚   â”œâ”€â”€ types/                          # TypeScript types
â”‚   â”‚   â”‚   â”œâ”€â”€ reasoning.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ knowledge.ts
â”‚   â”‚   â”‚   â””â”€â”€ performance.ts
â”‚   â”‚   â””â”€â”€ styles/                         # Styling
â”‚   â”‚       â”œâ”€â”€ globals.css
â”‚   â”‚       â”œâ”€â”€ components.css
â”‚   â”‚       â””â”€â”€ animations.css
â”‚   â””â”€â”€ dist/                               # Build output
â”‚
â”œâ”€â”€ training/                               # Model training pipeline
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_generation/                    # Training data generation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ synthetic_data.py               # Synthetic data generation
â”‚   â”‚   â”œâ”€â”€ vectionary_augmenter.py         # Vectionary data augmentation
â”‚   â”‚   â”œâ”€â”€ pattern_templates.py            # Pattern templates
â”‚   â”‚   â””â”€â”€ data_validator.py               # Data validation
â”‚   â”œâ”€â”€ training_scripts/                   # Training scripts
â”‚   â”‚   â”œâ”€â”€ train_semantic_classifier.py
â”‚   â”‚   â”œâ”€â”€ train_relation_extractor.py
â”‚   â”‚   â”œâ”€â”€ train_query_optimizer.py
â”‚   â”‚   â””â”€â”€ train_sentence_structure.py
â”‚   â”œâ”€â”€ configs/                            # Training configurations
â”‚   â”‚   â”œâ”€â”€ semantic_classifier.yaml
â”‚   â”‚   â”œâ”€â”€ relation_extractor.yaml
â”‚   â”‚   â”œâ”€â”€ query_optimizer.yaml
â”‚   â”‚   â””â”€â”€ sentence_structure.yaml
â”‚   â””â”€â”€ evaluation/                         # Model evaluation
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ accuracy_metrics.py
â”‚       â”œâ”€â”€ performance_metrics.py
â”‚       â””â”€â”€ benchmark_suite.py
â”‚
â”œâ”€â”€ benchmarks/                             # Performance testing
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ performance_tests.py                # Performance benchmarks
â”‚   â”œâ”€â”€ accuracy_tests.py                   # Accuracy validation
â”‚   â”œâ”€â”€ load_tests.py                       # Load testing
â”‚   â”œâ”€â”€ memory_tests.py                     # Memory usage tests
â”‚   â””â”€â”€ data/                               # Test data
â”‚       â”œâ”€â”€ logical_patterns.json
â”‚       â”œâ”€â”€ edge_cases.json
â”‚       â””â”€â”€ performance_datasets.json
â”‚
â”œâ”€â”€ tests/                                  # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ unit/                               # Unit tests
â”‚   â”‚   â”œâ”€â”€ test_semantic_parser.py
â”‚   â”‚   â”œâ”€â”€ test_logic_engine.py
â”‚   â”‚   â”œâ”€â”€ test_knowledge_graph.py
â”‚   â”‚   â””â”€â”€ test_inference_engine.py
â”‚   â”œâ”€â”€ integration/                        # Integration tests
â”‚   â”‚   â”œâ”€â”€ test_api.py
â”‚   â”‚   â”œâ”€â”€ test_reasoning_pipeline.py
â”‚   â”‚   â””â”€â”€ test_web_interface.py
â”‚   â””â”€â”€ fixtures/                           # Test fixtures
â”‚       â”œâ”€â”€ sample_queries.json
â”‚       â”œâ”€â”€ test_knowledge.json
â”‚       â””â”€â”€ expected_results.json
â”‚
â”œâ”€â”€ config/                                 # Configuration files
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py                         # Main settings
â”‚   â”œâ”€â”€ model_configs.py                    # Model configurations
â”‚   â”œâ”€â”€ api_configs.py                      # API configurations
â”‚   â””â”€â”€ performance_configs.py              # Performance settings
â”‚
â”œâ”€â”€ scripts/                                # Utility scripts
â”‚   â”œâ”€â”€ setup_environment.py                # Environment setup
â”‚   â”œâ”€â”€ download_models.py                  # Model downloading
â”‚   â”œâ”€â”€ benchmark_system.py                 # System benchmarking
â”‚   â””â”€â”€ deploy.py                           # Deployment script
â”‚
â””â”€â”€ docs/                                   # Documentation
    â”œâ”€â”€ README.md
    â”œâ”€â”€ API.md                              # API documentation
    â”œâ”€â”€ ARCHITECTURE.md                     # System architecture
    â”œâ”€â”€ PERFORMANCE.md                      # Performance guide
    â”œâ”€â”€ TRAINING.md                         # Model training guide
    â””â”€â”€ DEPLOYMENT.md                       # Deployment guide
```

## ðŸ”„ Migration Strategy from Current System

### **Phase 1: Drop-in Replacement**
```python
# ELMS-NEXT will provide a VectionaryParser-compatible interface
class ELMSNextParser:
    """Drop-in replacement for VectionaryParser"""
    
    def __init__(self, api_client=None):  # Maintain compatibility
        self.hybrid_parser = HybridSemanticParser()
        self.cache = LRUCache(maxsize=10000)
    
    def parse(self, text: str) -> ParsedStatement:
        """Same interface as current VectionaryParser"""
        # Use local models instead of API calls
        tree = self.hybrid_parser.parse(text)
        return self._convert_to_parsed_statement(tree)
```

### **Phase 2: Enhanced Features**
- Add new parsing capabilities not available in Vectionary
- Implement advanced caching and optimization
- Add custom model training capabilities

### **Phase 3: Full Migration**
- Remove Vectionary dependencies
- Optimize for local-only operation
- Add offline capabilities

## ðŸ§  Best Solutions for Sentence Structure Detection

### 1. **Hybrid Parsing Architecture**
```python
# core/semantic_parser/hybrid_parser.py
class HybridSemanticParser:
    """
    Combines multiple parsing strategies for maximum accuracy and speed
    """
    
    def __init__(self):
        # Fast rule-based parser for common patterns
        self.rule_parser = RuleBasedParser()
        
        # Custom-trained models for complex structures
        self.dependency_parser = DependencyParser()
        self.constituency_parser = ConstituencyParser()
        self.semantic_role_labeler = SemanticRoleLabeler()
        
        # Caching for performance
        self.cache = LRUCache(maxsize=10000)
    
    def parse(self, text: str) -> SemanticTree:
        # 1. Check cache first (fastest)
        if cached := self.cache.get(text):
            return cached
        
        # 2. Try rule-based parsing (very fast, high accuracy for common patterns)
        if result := self.rule_parser.parse(text):
            self.cache[text] = result
            return result
        
        # 3. Use custom models for complex structures
        result = self._parse_with_models(text)
        self.cache[text] = result
        return result
```

### 2. **Rule-Based Parser (Primary)**
```python
# core/semantic_parser/rule_based_parser.py
class RuleBasedParser:
    """
    Ultra-fast rule-based parser for common logical patterns
    Covers 80% of logical reasoning cases with 99.9% accuracy
    """
    
    def __init__(self):
        self.patterns = {
            # Possession patterns
            "possession": [
                r"(\w+)'s\s+(\w+)",  # "Mary's children"
                r"(\w+)\s+of\s+(\w+)",  # "children of Mary"
                r"(\w+)\s+has\s+(\w+)",  # "Mary has children"
            ],
            
            # Quantification patterns
            "quantification": [
                r"All\s+(\w+)\s+are\s+(\w+)",  # "All cats are mammals"
                r"Some\s+(\w+)\s+are\s+(\w+)",  # "Some birds can fly"
                r"Every\s+(\w+)\s+is\s+(\w+)",  # "Every student studies"
            ],
            
            # Relation patterns
            "relation": [
                r"(\w+)\s+is\s+(\w+)\s+of\s+(\w+)",  # "Alice is parent of Bob"
                r"(\w+)\s+gives\s+(\w+)\s+to\s+(\w+)",  # "John gives book to Mary"
                r"(\w+)\s+studies\s+(\w+)",  # "Maria studies regularly"
            ],
            
            # Question patterns
            "question": [
                r"Who\s+are\s+(\w+)\s+who\s+(\w+)",  # "Who are students who study"
                r"What\s+(\w+)\s+do\s+we\s+have",  # "What mammals do we have"
                r"Who\s+makes\s+(\w+)",  # "Who makes decisions"
            ]
        }
    
    def parse(self, text: str) -> Optional[SemanticTree]:
        for pattern_type, patterns in self.patterns.items():
            for pattern in patterns:
                if match := re.match(pattern, text, re.IGNORECASE):
                    return self._build_semantic_tree(pattern_type, match, text)
        return None
```

### 3. **Custom Dependency Parser**
```python
# models/sentence_structure/dependency_parser.py
class DependencyParser:
    """
    Custom-trained dependency parser optimized for logical reasoning
    Smaller, faster, more accurate than general-purpose parsers
    """
    
    def __init__(self):
        self.model = self._load_model()
        self.vocab = self._load_vocab()
    
    def parse(self, text: str) -> DependencyTree:
        # Tokenize and encode
        tokens = self._tokenize(text)
        encoded = self._encode(tokens)
        
        # Predict dependencies
        dependencies = self.model.predict(encoded)
        
        # Build dependency tree
        return self._build_tree(tokens, dependencies)
```

### 4. **Semantic Role Labeler**
```python
# models/sentence_structure/semantic_role_labeler.py
class SemanticRoleLabeler:
    """
    Custom semantic role labeling for logical relations
    Trained specifically on logical reasoning patterns
    """
    
    def __init__(self):
        self.model = self._load_model()
        self.role_mappings = {
            'agent': 'subject',
            'patient': 'object',
            'theme': 'predicate',
            'goal': 'indirect_object',
            'modifier': 'adjective',
            'possessive': 'possessor'
        }
    
    def label_roles(self, dependency_tree: DependencyTree) -> Dict[str, str]:
        # Extract semantic roles from dependency tree
        roles = {}
        
        for token in dependency_tree.tokens:
            if token.dep in self.role_mappings:
                role = self.role_mappings[token.dep]
                roles[role] = token.text.lower()
        
        return roles
```

### 5. **Pattern Matching Engine**
```python
# core/semantic_parser/pattern_matcher.py
class PatternMatcher:
    """
    High-performance pattern matching for logical structures
    Uses compiled regex and optimized matching algorithms
    """
    
    def __init__(self):
        self.compiled_patterns = self._compile_patterns()
        self.pattern_cache = {}
    
    def match_pattern(self, text: str) -> Optional[PatternMatch]:
        # Use compiled patterns for maximum speed
        for pattern_name, pattern in self.compiled_patterns.items():
            if match := pattern.search(text):
                return PatternMatch(
                    name=pattern_name,
                    groups=match.groups(),
                    span=match.span()
                )
        return None
```

### 6. **Vectionary-Compatible Output Format**
```python
# core/semantic_parser/vectionary_compat.py
class VectionaryCompatibleParser:
    """
    Generates Vectionary-compatible output format for seamless migration
    """
    
    def parse(self, text: str) -> Dict:
        """Generate Vectionary-style semantic tree"""
        # Parse with local models
        local_tree = self.hybrid_parser.parse(text)
        
        # Convert to Vectionary format
        return {
            'id': f"{local_tree.lemma}_{local_tree.pos}_{local_tree.index}",
            'char_index': local_tree.char_index,
            'definition': local_tree.definition,
            'dependency': local_tree.dependency,
            'index': local_tree.index,
            'lemma': local_tree.lemma,
            'mood': local_tree.mood,
            'pos': local_tree.pos,
            'tense': local_tree.tense,
            'text': local_tree.text,
            'children': self._convert_children(local_tree.children)
        }
    
    def _convert_children(self, children: List) -> List[Dict]:
        """Convert children to Vectionary format"""
        vectionary_children = []
        for child in children:
            vectionary_children.append({
                'text': child.text,
                'role': child.role,
                'pos': child.pos,
                'number': child.number,
                'person': child.person,
                'children': self._convert_children(child.children) if child.children else []
            })
        return vectionary_children
```

## ðŸš€ Key Implementation Strategies

### 1. **Performance Optimization**
- **Caching**: Multi-level caching (L1: memory, L2: Redis, L3: disk)
- **Compilation**: Pre-compile common patterns and rules
- **Indexing**: O(1) lookups for facts and relations
- **Parallelization**: Parallel query execution where safe

### 2. **Accuracy Enhancement**
- **Specialized Training**: Models trained specifically on logical reasoning
- **Pattern Templates**: Comprehensive pattern library
- **Validation**: Multi-layer validation of parsing results
- **Fallback Strategies**: Graceful degradation for edge cases

### 3. **Scalability Design**
- **Stateless Architecture**: Horizontal scaling capability
- **Microservices**: Modular, independently scalable components
- **Load Balancing**: Intelligent request distribution
- **Resource Management**: Efficient memory and CPU usage

## ðŸ“Š Expected Performance Metrics

- **Latency**: <10ms average, <50ms 99th percentile
- **Accuracy**: >99% on logical reasoning tasks
- **Throughput**: >1000 requests/second
- **Memory**: <500MB for full system
- **Model Size**: <50MB total for all models

## ðŸ› ï¸ Development Phases

### Phase 1: Core Engine (2-3 weeks)
- [ ] Rule-based parser implementation
- [ ] Basic Prolog engine optimization
- [ ] Caching system
- [ ] API foundation

### Phase 2: Custom Models (3-4 weeks)
- [ ] Training data generation
- [ ] Model training pipelines
- [ ] Model optimization
- [ ] Integration testing

### Phase 3: Advanced Features (2-3 weeks)
- [ ] Knowledge graph implementation
- [ ] Advanced inference strategies
- [ ] Performance optimization
- [ ] Web interface

### Phase 4: Production (1-2 weeks)
- [ ] Comprehensive testing
- [ ] Performance benchmarking
- [ ] Production deployment
- [ ] Monitoring and alerting

This architecture provides a complete roadmap for building a high-performance logical reasoning system that addresses Vectionary's limitations while maintaining accuracy and speed.

## ðŸ“˜ Semantic Tree Schema (with Definitions)

To enable true reasoning and deterministic conversion to logic, include rich dictionary-style definitions on each node and use them systematically.

### Node fields
```json
{
  "ID": "make_V_1.1",
  "text": "make",
  "lemma": "make",
  "pos": "VERB",
  "dependency": "ROOT",
  "index": 3,
  "char_index": 12,
  "mood": "INDICATIVE",
  "tense": "PRESENT",
  "role": "root",
  "definition": "to build, construct, produce, or originate",
  "sense_id": "make.v.01",           
  "frame_id": "Causation|Creation",  
  "ontology_refs": [
    {"kb": "ELMS-ONT", "concept_id": "ELMS:CREATE", "confidence": 0.92}
  ],
  "children": [
    {"role": "agent", "text": "Directors", "definition": "members of a board with decision authority"},
    {"role": "patient", "text": "decisions", "definition": "acts of making a choice"}
  ]
}
```

### How "definition" improves reasoning
- Predicate grounding: map surface forms to canonical predicates using definition cues
  - Example: definition contains "produce/originate" â†’ predicate_hint: "produce/ originate"
- Sense disambiguation: choose sense_id aligned with role structure and definition terms
- Rule synthesis: extract hypernyms/entailments from definitions to propose rules
  - Example: "director: member of a board with decision authority" â†’ rule: director(X) â†’ makes_decisions(X)
- Ontology linking: attach `ontology_refs` based on definition similarity to ELMS ontology
- Confidence shaping: boost conversions when definition aligns with observed roles

### Deterministic conversion using definitions
```python
# core/semantic_parser/definition_grounding.py
class DefinitionGrounder:
    def ground_predicate(self, node) -> str:
        text = (node.get("definition") or "").lower()
        lemma = node.get("lemma", "").lower()
        # Priority 1: curated mapping by definition keywords
        if any(k in text for k in ["produce", "originate", "create"]):
            return "produce"
        if any(k in text for k in ["decide", "decision", "determine"]):
            return "make_decisions"
        # Priority 2: frame/roleset hints
        frame = node.get("frame_id") or ""
        if "Giving" in frame:
            return "give"
        # Priority 3: fallback to lemma
        return lemma

    def propose_rules_from_definition(self, noun_node) -> list[str]:
        defs = (noun_node.get("definition") or "").lower()
        rules = []
        if "decision authority" in defs or "authority to decide" in defs:
            rules.append("makes_decisions(X) :- director(X).")
        if "offspring" in defs and noun_node.get("lemma") == "child":
            rules.append("children(Y,X) :- parent(X,Y).")
        return rules
```

### Storage recommendations
- Always populate `definition` for content words (VERB, NOUN, ADJ) when available
- Persist `sense_id`, `frame_id`, and `ontology_refs` for auditability
- Cache grounding results by `canonical_key` (lemma+roles+args)

### Query-time use
- Use definition-grounded predicate names for query formation to avoid collective nouns (e.g., "directors" â†’ variable over `director(X)`)
- When answer type is ambiguous, prefer definitions that imply individual-level predicates

